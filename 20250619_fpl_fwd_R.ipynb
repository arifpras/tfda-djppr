{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR1PQnaLfcPLKPmUJpVNjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arifpras/tfda-djppr/blob/main/20250619_fpl_fwd_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiSTq01DJGRo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive  # Import the drive module from google.colab so we can access Google Drive\n",
        "\n",
        "drive.mount('/content/drive')   # Mount (connect) your Google Drive to the path /content/drive so files can be accessed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "setwd(\"/content/drive/MyDrive/00fpl\")  # Set the working directory to the specified folder in your Google Drive\n",
        "\n",
        "getwd()                                # Show the current working directory to confirm the change"
      ],
      "metadata": {
        "id": "CQ2fC9tnKK0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(readr)   # Load the 'readr' package, which provides functions to read data (like CSV files)\n",
        "\n",
        "library(dplyr)   # Load the 'dplyr' package, useful for data manipulation (filtering, selecting, grouping, etc.)\n",
        "\n",
        "db00 <- read_csv(\"/content/drive/MyDrive/00fpl/db00all_fpl.csv\", show_col_types = FALSE)\n",
        "# Read the CSV file from your Google Drive into a data frame called 'db00'\n",
        "# 'show_col_types = FALSE' hides the column type message\n",
        "\n",
        "# db00 <- read_csv(\"https://raw.githubusercontent.com/arifpras/tfda-djppr/refs/heads/main/courses/workshop01/db00all_fpl.csv\", show_col_types = FALSE)\n",
        "# (Optional alternative) Load the same CSV file directly from a GitHub URL instead of Google Drive"
      ],
      "metadata": {
        "id": "7OK7ATfuKQ-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glimpse(db00)  # Quickly display the structure of the 'db00' data frame: column names, types, and example values"
      ],
      "metadata": {
        "id": "HbBCTgUxK9Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "important_vars <- c(\n",
        "  \"name\", \"total_points\", \"position\", \"team\", \"x_p\", \"assists\", \"bonus\", \"bps\",\n",
        "  \"clean_sheets\", \"creativity\", \"expected_assists\", \"expected_goal_involvements\",\n",
        "  \"expected_goals\", \"expected_goals_conceded\", \"goals_conceded\", \"goals_scored\",\n",
        "  \"influence\", \"minutes\", \"own_goals\", \"penalties_missed\",\n",
        "  \"penalties_saved\", \"red_cards\", \"saves\", \"selected\", \"starts\", \"team_a_score\",\n",
        "  \"team_h_score\", \"threat\", \"transfers_balance\", \"value\"\n",
        ")\n",
        "# Define a list of important columns to keep from the dataset\n",
        "\n",
        "db01 <- db00 %>%\n",
        "  select(all_of(important_vars)) %>%              # Keep only the specified columns from db00\n",
        "  filter(minutes != 0, position == \"FWD\", value >= 36) %>%  # Keep only players with non-zero minutes, who play as forwards, and have value >= 36\n",
        "  mutate(value = value / 10) %>%                  # Convert player value to original scale (e.g., 100 â†’ 10.0)\n",
        "  relocate(total_points)                          # Move 'total_points' column to the front\n",
        "# Create a new filtered and cleaned dataset called db01\n",
        "\n",
        "glimpse(db01)  # Display the structure of db01: column names, types, and example values"
      ],
      "metadata": {
        "id": "6wV6MQ-NMWG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db01 %>% head()  # Show the first 6 rows of the cleaned dataset 'db01' to get a quick look at the data"
      ],
      "metadata": {
        "id": "DYgvXGWqMfZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db01 %>%\n",
        "  arrange(desc(total_points)) %>%                     # Sort the players from highest to lowest total points\n",
        "  select(name, team, position, value, total_points)   # Select only key columns to display: name, team, position, value, and total points"
      ],
      "metadata": {
        "id": "_4RpiZDXMoKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"colorspace\")  # (Run once if not yet installed) Installs the 'colorspace' package for color customization\n",
        "\n",
        "library(ggplot2)     # Load ggplot2 for plotting\n",
        "library(colorspace)  # Load colorspace for advanced color manipulation\n",
        "library(dplyr)       # Load dplyr for data manipulation\n",
        "\n",
        "# Filter and plot\n",
        "db01 %>%\n",
        "  select(-name) %>%  # Exclude the 'name' column to simplify the plot\n",
        "  ggplot(aes(x = team, y = total_points)) +  # Start a ggplot: team on x-axis (flipped later), total points on y-axis\n",
        "  geom_boxplot(\n",
        "    aes(\n",
        "      fill = after_scale(desaturate(lighten(color, 0.7), 0.7))  # Use a lightened and desaturated version of the default fill color\n",
        "    ),\n",
        "    size = 1,      # Thickness of boxplot lines\n",
        "    color = \"grey50\"  # Border color of boxplots\n",
        "  ) +\n",
        "  scale_fill_manual(values = NULL) +  # Allow manual fill scale (required when using after_scale, even if NULL)\n",
        "  # facet_wrap(~ obsvar, scales = \"free\", nrow = 1) +  # (Optional) Facet if you'd like to split by another variable\n",
        "  theme_light() +  # Use a clean light theme\n",
        "  labs(\n",
        "    title = \"Boxplot of Total Points by Team (FWD)\",  # Plot title\n",
        "    x = \"\\nTeam\",  # X-axis label\n",
        "    y = \"\",        # No Y-axis label\n",
        "    color = NULL   # No legend title\n",
        "  ) +\n",
        "  coord_flip() +  # Flip the coordinates to make team names readable (horizontal boxplots)\n",
        "  theme(\n",
        "    axis.text.x = element_text(size = 8),           # Customize x-axis text size\n",
        "    axis.ticks.x = element_blank(),                 # Remove x-axis ticks\n",
        "    axis.line.x = element_blank(),                  # Remove x-axis lines\n",
        "    axis.title.x = element_text(size = 7),          # X-axis title size\n",
        "    axis.text.y = element_text(size = 8),           # Y-axis (team names) text size\n",
        "    axis.title.y = element_text(size = 7),          # Y-axis title size\n",
        "    axis.line.y = element_blank(),                  # Remove y-axis lines\n",
        "    plot.title = element_text(hjust = 0, size = 16, face = \"bold\"),  # Title aligned left, bold, larger size\n",
        "    plot.title.position = \"plot\",                   # Title position\n",
        "    strip.text.x = element_text(size = 8),          # Facet strip label size (if faceting)\n",
        "    panel.grid.major.y = element_line(color = \"grey90\"),  # Light gridlines for readability\n",
        "    panel.spacing = unit(1, \"lines\"),               # Spacing between facets (if used)\n",
        "    legend.position = \"none\"                        # Hide legend\n",
        "  )"
      ],
      "metadata": {
        "id": "4oboT35bMt9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db01 %>%\n",
        "  group_by(team) %>%  # Group the data by 'team'\n",
        "\n",
        "  summarise(\n",
        "    count_players = n(),                                    # Number of forwards in each team\n",
        "    min_points = min(total_points, na.rm = TRUE),           # Minimum total points\n",
        "    q1 = quantile(total_points, 0.25, na.rm = TRUE),        # 25th percentile (Q1)\n",
        "    q2_median = median(total_points, na.rm = TRUE),         # Median (Q2)\n",
        "    q3 = quantile(total_points, 0.75, na.rm = TRUE),        # 75th percentile (Q3)\n",
        "    q4 = max(total_points, na.rm = TRUE),                   # Maximum value (same as max_points, redundant here)\n",
        "    max_points = max(total_points, na.rm = TRUE),           # Maximum total points (repeated for clarity)\n",
        "    mean_points = mean(total_points, na.rm = TRUE),         # Mean total points\n",
        "    value_weighted_avg = weighted.mean(total_points, w = value, na.rm = TRUE)  # Value-weighted average of total points\n",
        "  ) %>%\n",
        "  arrange(desc(q2_median))  # Sort the results by median total points (highest team medians first)"
      ],
      "metadata": {
        "id": "uA-E3yyPM6rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"stargazer\")  # (Run once) Install the 'stargazer' package for beautiful summary tables\n",
        "\n",
        "library(stargazer)  # Load the stargazer package\n",
        "\n",
        "db01 %>%\n",
        "  as.data.frame() %>%                            # Convert tibble to standard data frame (stargazer prefers base data frames)\n",
        "  stargazer(type = 'text',                      # Output the summary as plain text (other options: 'html', 'latex')\n",
        "            out = \"descsumm01_fwd.txt\",         # Save the summary output to a text file named \"descsumm01_fwd.txt\"\n",
        "            digits = 1)                         # Round all numeric summaries to 1 decimal place"
      ],
      "metadata": {
        "id": "2LXPmCKpNFd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"parameters\")  # (Run once) Install the 'parameters' package to compute advanced descriptive statistics\n",
        "\n",
        "library(dplyr)       # Load dplyr for data manipulation\n",
        "library(parameters)  # Load parameters for descriptive summary functions\n",
        "\n",
        "# Get the summary as a data frame\n",
        "descsumm02 <- db01 %>%\n",
        "  select(where(is.numeric)) %>%      # Select only numeric columns from db01\n",
        "  describe_distribution()            # Generate descriptive stats (mean, SD, skewness, kurtosis, etc.)\n",
        "\n",
        "descsumm02  # View the summary table\n",
        "\n",
        "# Save it as plain text\n",
        "capture.output(\n",
        "  print(descsumm02, digits = 1),     # Format the output with 1 decimal precision\n",
        "  file = \"descsumm02_fwd.txt\"        # Save the printed summary to a file named \"descsumm02_fwd.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "Gf0k6P_GNOhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"corrr\")  # (Run once) Install the 'corrr' package to compute and format correlation matrices\n",
        "\n",
        "library(corrr)  # Load the corrr package\n",
        "\n",
        "corr01 <- db01 %>%\n",
        "  select(where(is.numeric)) %>%  # Keep only numeric columns from db01\n",
        "  correlate() %>%                # Compute pairwise correlations between all numeric variables\n",
        "  # shave() %>%                 # (Optional) Remove the upper triangle of the correlation matrix\n",
        "  fashion()                     # Format the correlation matrix for cleaner display (aligns numbers, adds spacing)\n",
        "\n",
        "corr01  # Display the formatted correlation table\n",
        "\n",
        "# Save the output as a plain text file\n",
        "capture.output(print(corr01), file = \"corr01_fwd.txt\")  # Write the result to \"corr01_fwd.txt\""
      ],
      "metadata": {
        "id": "-rYrIJTPNU0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db01 %>%\n",
        "  select(where(is.numeric)) %>%         # Select only numeric columns from db01\n",
        "  correlate() %>%                        # Compute pairwise correlations between numeric variables\n",
        "  as.data.frame() %>%                    # Convert the correlation matrix to a regular data frame\n",
        "  write.csv(\"corr01_fwd.csv\", row.names = FALSE)  # Save it as a CSV file without row names"
      ],
      "metadata": {
        "id": "nSpLeJdENeiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"viridis\")  # (Run once) Install the 'viridis' package for colorblind-friendly color scales\n",
        "\n",
        "library(corrr)     # For calculating correlations\n",
        "library(dplyr)     # For data manipulation\n",
        "library(tidyr)     # For reshaping data\n",
        "library(ggplot2)   # For plotting\n",
        "library(viridis)   # For advanced color palettes (colorblind-friendly)\n",
        "\n",
        "# Step 1: Compute correlations\n",
        "corr_matrix <- db01 %>%\n",
        "  select(where(is.numeric)) %>%  # Select only numeric columns\n",
        "  correlate()                    # Compute correlation matrix\n",
        "\n",
        "# Step 2: Reshape to long format (for ggplot heatmap)\n",
        "corr_long <- corr_matrix %>%\n",
        "  pivot_longer(-term, names_to = \"variable\", values_to = \"correlation\")  # Convert wide matrix to long format\n",
        "\n",
        "# Step 3: Create heatmap plot object\n",
        "corr_plot <- ggplot(corr_long, aes(x = term, y = variable, fill = correlation)) +\n",
        "  geom_tile(color = \"white\") +                                   # Create colored squares for each correlation\n",
        "  scale_fill_viridis_c(option = \"D\", limits = c(-1, 1), name = \"Correlation\") +  # Apply viridis color scale from -1 to 1\n",
        "  # coord_fixed() +                                                # Fix aspect ratio for square tiles\n",
        "  theme_minimal() +                                              # Use a clean minimal theme\n",
        "  theme(\n",
        "    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Rotate x-axis labels for readability\n",
        "    axis.text.y = element_text(size = 8),\n",
        "    panel.grid = element_blank(),\n",
        "    plot.title = element_text(size = 14, face = \"bold\", hjust = 0),\n",
        "    legend.title = element_text(size = 9),\n",
        "    legend.text = element_text(size = 8)\n",
        "  ) +\n",
        "  labs(title = \"Correlation Heatmap\", x = \"\", y = \"\")  # Set title and remove axis labels\n",
        "\n",
        "corr_plot  # Display the heatmap in the notebook\n",
        "\n",
        "# Step 4: Save to PDF\n",
        "ggsave(\"heatmap01_fwd.pdf\", plot = corr_plot, width = 11.7, height = 8.3)  # Export the plot to a landscape A4 PDF"
      ],
      "metadata": {
        "id": "FFcZx1pnNqBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# library(tidyverse)  # (Optional) Load the full tidyverse suite if needed\n",
        "library(tidyr)        # Load tidyr for data reshaping functions like pivot_longer()\n",
        "\n",
        "db02 <- db01 %>%\n",
        "  select(-name) %>%                  # Remove the 'name' column to simplify the reshaped data\n",
        "  relocate(team, position) %>%      # Move 'team' and 'position' columns to the front\n",
        "  pivot_longer(                     # Reshape the data from wide to long format:\n",
        "    cols = total_points:value,      # Convert all columns from 'total_points' to 'value' into key-value pairs\n",
        "    names_to = \"obsvar\",            # Store original column names in a new column called 'obsvar'\n",
        "    values_to = \"obsval\"            # Store the corresponding values in a column called 'obsval'\n",
        "  )\n",
        "\n",
        "glimpse(db02)  # Display the structure of the reshaped dataset"
      ],
      "metadata": {
        "id": "6jDE_mOAN3Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "important_vars <- c(\n",
        "  \"total_points\", \"team\", \"assists\", \"creativity\",\n",
        "  \"expected_assists\", \"expected_goals\", \"goals_scored\", \"influence\",\n",
        "  \"minutes\", \"own_goals\", \"penalties_missed\", \"selected\", \"starts\",\n",
        "  \"threat\", \"transfers_balance\", \"value\"\n",
        ")\n",
        "# Define a list of important variables (column names) to include in the new dataset\n",
        "\n",
        "db03 <- db01 %>%\n",
        "  select(all_of(important_vars)) %>%  # Select only the specified variables from db01\n",
        "  relocate(total_points)              # Move 'total_points' column to the front for easier reference\n",
        "\n",
        "glimpse(db03)  # Display the structure of the new dataset (column types and example values)"
      ],
      "metadata": {
        "id": "ygGREXNIOBh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db03$team <- factor(db03$team)  # Convert the 'team' column to a factor (categorical variable)\n",
        "\n",
        "db03$team <- relevel(db03$team, ref = \"Man City\")\n",
        "# Set \"Man City\" as the reference category for the 'team' factor.\n",
        "# This means all other team coefficients in the regression will be compared to \"Man City\"\n",
        "\n",
        "ols_fwd_base <- lm(total_points ~ ., data = db03)\n",
        "# Fit a linear regression model predicting total_points using all other variables in db03\n",
        "# (The \".\" means \"use all remaining columns as predictors\")\n",
        "\n",
        "# ols_fwd_robust <- lm_robust(\n",
        "#   total_points ~ ., data = db03, se_type = \"stata\"\n",
        "# )\n",
        "# (Optional) Robust version using heteroskedasticity-consistent standard errors (commented out)\n",
        "\n",
        "summary(ols_fwd_base)  # Print the summary of the OLS regression model\n",
        "\n",
        "# summary(ols_fwd_robust)\n",
        "# Print the robust regression summary (if using the lm_robust version)"
      ],
      "metadata": {
        "id": "c4l-IL_nOMlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load required libraries\n",
        "# install.packages(\"glmnet\")  # (Run once if not installed)\n",
        "library(glmnet)  # For regularized regression like LASSO\n",
        "library(dplyr)   # For data manipulation\n",
        "\n",
        "# Prepare data\n",
        "# (Uncomment and adjust if you want a custom version of db_lasso)\n",
        "# db_lasso <- db01 %>%\n",
        "#   select(total_points, team, x_p, assists, bonus, bps, clean_sheets, creativity,\n",
        "#          expected_assists, expected_goals, goals_scored, influence,\n",
        "#          minutes, own_goals, penalties_missed, selected, starts, threat,\n",
        "#          transfers_balance, value) %>%\n",
        "#   na.omit()  # Remove rows with missing values\n",
        "\n",
        "# Convert categorical variable 'team' to dummy variables\n",
        "x <- model.matrix(total_points ~ ., data = db03)[, -1]  # Create matrix of predictors (excluding intercept column)\n",
        "y <- db_lasso$total_points  # Target variable (total points)\n",
        "\n",
        "# âš™ï¸ Fit LASSO using cross-validation\n",
        "set.seed(123)  # For reproducibility\n",
        "cv_fit <- cv.glmnet(x, y, alpha = 1, standardize = TRUE)\n",
        "# Perform LASSO (alpha = 1) with automatic lambda tuning via cross-validation\n",
        "\n",
        "# Optimal lambda\n",
        "best_lambda <- cv_fit$lambda.min  # Best lambda minimizing mean cross-validated error\n",
        "cat(\"Best lambda:\", best_lambda, \"\\n\")\n",
        "\n",
        "# Plot cross-validation error curve\n",
        "plot(cv_fit)  # Shows how model error changes as lambda increases\n",
        "\n",
        "# Extract coefficients at best lambda\n",
        "coef(cv_fit, s = \"lambda.min\")  # Show which variables are kept/shrunk\n",
        "\n",
        "# Predict fitted values (optional)\n",
        "pred <- predict(cv_fit, newx = x, s = \"lambda.min\")  # Make predictions using the selected lambda"
      ],
      "metadata": {
        "id": "WKKkswDGOWXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What this does:\n",
        "\n",
        "- Automatically selects the most predictive variables for total_points using LASSO regularization.\n",
        "- Shrinks less important coefficients to zero â€” great for feature selection.\n",
        "- Uses cross-validation to find the optimal penalty (lambda.min)."
      ],
      "metadata": {
        "id": "Qv6xztTCO2lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `lasso_coef` is your sparse matrix from coef(cv_fit, s = \"lambda.min\")\n",
        "lasso_coef <- coef(cv_fit, s = \"lambda.min\")\n",
        "# Extract the coefficients from the best LASSO model (based on lambda.min)\n",
        "\n",
        "# Convert to a tidy data frame\n",
        "coef_df <- as.matrix(lasso_coef) %>%                  # Convert the sparse matrix to a regular matrix\n",
        "  as.data.frame() %>%                                 # Convert matrix to data frame\n",
        "  tibble::rownames_to_column(var = \"feature\") %>%     # Move row names (variable names) into a column called \"feature\"\n",
        "  rename(coefficient = s0)                            # Rename the column holding coefficients to \"coefficient\"\n",
        "\n",
        "# Optional: filter only non-zero coefficients\n",
        "coef_df_nonzero <- coef_df %>%\n",
        "  filter(coefficient != 0)  # Keep only the features selected by the LASSO (i.e., those with non-zero coefficients)\n",
        "\n",
        "# View\n",
        "print(coef_df_nonzero)  # Display the non-zero coefficients and their associated features"
      ],
      "metadata": {
        "id": "f6ySSI90OqV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"estimatr\")  # (Run once) Install for robust regression tools\n",
        "library(estimatr)  # Load package (used if running lm_robust)\n",
        "\n",
        "# install.packages(\"modelsummary\")  # (Optional) Install for pretty regression tables\n",
        "# library(modelsummary)  # Load modelsummary (used if you want clean tables with stars)\n",
        "\n",
        "# ðŸ’¡ Optional robust version using lm_robust (commented out)\n",
        "# ols_fwd_lasso <- lm_robust(\n",
        "#     total_points ~ team + assists + creativity + expected_assists + expected_goals +\n",
        "#       goals_scored + influence + minutes + own_goals + penalties_missed + starts +\n",
        "#       threat + transfers_balance + value, data = db03, se_type = \"stata\")\n",
        "\n",
        "# Basic OLS regression using only variables selected by LASSO\n",
        "ols_fwd_lasso <- lm(\n",
        "  total_points ~ team + assists + creativity + expected_assists + expected_goals +\n",
        "    goals_scored + influence + minutes + own_goals + penalties_missed + starts +\n",
        "    threat + transfers_balance + value, data = db03)\n",
        "\n",
        "# View summary of the model: coefficients, RÂ², significance levels, etc.\n",
        "summary(ols_fwd_lasso)\n",
        "\n",
        "# (Optional) Generate a clean regression table with significance stars\n",
        "# modelsummary(ols_fwd_lasso, stars = TRUE)"
      ],
      "metadata": {
        "id": "A3dgKpUsO-mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This version runs an OLS regression using only the LASSO-retained predictors, helping you evaluate their statistical significance more traditionally (p-values, RÂ², etc.)."
      ],
      "metadata": {
        "id": "yhL9T1TLPF3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ols_fwdsw <- step(ols_fwd_base, direction = \"both\")\n",
        "ols_fwdsw <- step(ols_fwd_base, direction = \"both\")\n",
        "# Perform stepwise regression starting from the full model (ols_fwd_base)\n",
        "# direction = \"both\" allows both forward selection and backward elimination\n",
        "# The algorithm chooses the best subset of predictors based on AIC (Akaike Information Criterion)\n",
        "\n",
        "summary(ols_fwdsw)\n",
        "# Show the summary of the final model chosen by stepwise selection:\n",
        "# includes coefficients, p-values, RÂ², and diagnostic metrics"
      ],
      "metadata": {
        "id": "KuptCYftPPGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method automatically selects a simpler, more efficient model by removing or adding predictors that improve the model's AIC. It's useful when you're unsure which combination of predictors performs best."
      ],
      "metadata": {
        "id": "LSNkGbGIPWwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"estimatr\")  # (Run once) For robust regression tools\n",
        "library(estimatr)  # Load for lm_robust if needed\n",
        "\n",
        "# install.packages(\"modelsummary\")  # (Optional) For clean regression output\n",
        "# library(modelsummary)\n",
        "\n",
        "# (Optional robust version using heteroskedasticity-consistent SEs)\n",
        "# ols_fwd_stepwise <- lm_robust(\n",
        "#     total_points ~ assists + creativity + expected_goals + goals_scored +\n",
        "#       influence + minutes + own_goals + penalties_missed + selected +\n",
        "#       starts + threat + transfers_balance + value, data = db03, se_type = \"stata\")\n",
        "\n",
        "# Standard OLS regression with predictors selected from stepwise procedure\n",
        "ols_fwd_stepwise <- lm(\n",
        "  total_points ~ assists + creativity + expected_goals + goals_scored +\n",
        "    influence + minutes + own_goals + penalties_missed + selected +\n",
        "    starts + threat + value, data = db03)\n",
        "\n",
        "summary(ols_fwd_stepwise)\n",
        "# View the summary: coefficients, significance levels, RÂ², and diagnostics\n",
        "\n",
        "# (Optional) Produce a nicely formatted regression table\n",
        "# modelsummary(ols_fwd_stepwise, stars = TRUE)"
      ],
      "metadata": {
        "id": "Iv_NuJmhPV4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is leaner, based on variables chosen by the stepwise AIC approach â€” keeping only those that statistically and economically contribute to explaining total_points."
      ],
      "metadata": {
        "id": "1WdZVcYqPl-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"MuMIn\")  # (Run once) Install 'MuMIn' for model selection tools\n",
        "library(MuMIn)  # Load the MuMIn package\n",
        "\n",
        "options(na.action = \"na.fail\")\n",
        "# Required by 'dredge': forces R to fail if missing data exists (ensures full variable combinations are valid)\n",
        "\n",
        "ols_mumin <- get.models(\n",
        "  dredge(ols_fwd_base, rank = \"AICc\"), 1\n",
        ")[[1]]\n",
        "# Perform exhaustive model search using 'dredge', ranked by AICc (corrected AIC for small samples)\n",
        "# 'get.models(..., 1)[[1]]' extracts the **best model** (lowest AICc) from the full model set\n",
        "\n",
        "summary(ols_mumin)\n",
        "# Display the summary of the best model: coefficients, RÂ², significance levels, and residuals"
      ],
      "metadata": {
        "id": "5Rsecs9BPoxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This approach performs an automated model selection across all possible combinations of predictors, not just forward/backward paths â€” using AICc as the selection criterion."
      ],
      "metadata": {
        "id": "MuMYrJWCPx0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"estimatr\")  # (Run once) Install estimatr for robust regression\n",
        "library(estimatr)  # Load estimatr (if using lm_robust)\n",
        "\n",
        "# install.packages(\"modelsummary\")  # (Optional) Install for nice summary tables\n",
        "# library(modelsummary)\n",
        "\n",
        "# Robust version (commented out): for heteroskedasticity-consistent standard errors\n",
        "# ols_fwd_dredge <- lm_robust(\n",
        "#     total_points ~ assists + creativity + expected_goals + goals_scored +\n",
        "#       influence + minutes + own_goals + penalties_missed + selected +\n",
        "#       starts + threat + value, data = db03, se_type = \"stata\")\n",
        "\n",
        "# Standard OLS model with predictors chosen via MuMIn::dredge (best AICc model)\n",
        "ols_fwd_dredge <- lm(\n",
        "  total_points ~ assists + creativity + expected_goals + goals_scored +\n",
        "    influence + minutes + own_goals + penalties_missed + selected +\n",
        "    starts + threat + value, data = db03)\n",
        "\n",
        "summary(ols_fwd_dredge)\n",
        "# View regression output: coefficient estimates, significance, RÂ², residual stats\n",
        "\n",
        "# (Optional) Clean output table with significance stars\n",
        "# modelsummary(ols_fwd_dredge, stars = TRUE)"
      ],
      "metadata": {
        "id": "374xzagTP2EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final model reflects the most AICc-efficient subset from your original full model, selected via MuMIn::dredge."
      ],
      "metadata": {
        "id": "K2ncxDWWP96A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"olsrr\")  # (Run once) Install 'olsrr' for stepwise regression diagnostics\n",
        "library(olsrr)  # Load the olsrr package\n",
        "\n",
        "ols_step_both_p(ols_fwd_base)\n",
        "# Perform stepwise regression based on p-values:\n",
        "# - Starts with the full model (ols_fwd_base)\n",
        "# - Adds/removes variables one at a time\n",
        "# - Chooses variables based on their statistical significance (p-value thresholds)\n",
        "# - Stops when no further significant improvements can be made\n",
        "\n",
        "# Output:\n",
        "# - A step-by-step log of which variables were added or removed\n",
        "# - Final model summary (AIC, RÂ², etc.)"
      ],
      "metadata": {
        "id": "8x7DvHaFP_3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives a p-value-based alternative to AIC-based stepwise methods â€” useful for quick, interpretable model refinement based on significance thresholds."
      ],
      "metadata": {
        "id": "Y8jysjT0QH_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"estimatr\")  # (Run once) Install for robust standard error options\n",
        "library(estimatr)  # Load for lm_robust (optional robust regression)\n",
        "\n",
        "# install.packages(\"modelsummary\")  # (Optional) Install for clean summary tables\n",
        "# library(modelsummary)\n",
        "\n",
        "# (Optional) Robust OLS version using heteroskedasticity-consistent SEs\n",
        "# ols_fwd_olsrr <- lm_robust(\n",
        "#     total_points ~ influence + assists + goals_scored + minutes + penalties_missed +\n",
        "#       threat + starts + own_goals + creativity + value +\n",
        "#       expected_goals + selected, data = db03, se_type = \"stata\")\n",
        "\n",
        "# Standard OLS model using predictors selected via olsrr::ols_step_both_p()\n",
        "ols_fwd_olsrr <- lm(\n",
        "  total_points ~ influence + assists + goals_scored + minutes + penalties_missed +\n",
        "    threat + starts + own_goals + creativity + value +\n",
        "    expected_goals + selected, data = db03)\n",
        "\n",
        "summary(ols_fwd_olsrr)\n",
        "# Show regression summary: estimates, standard errors, significance, and fit stats\n",
        "\n",
        "# (Optional) Display a clean summary table with significance stars\n",
        "# modelsummary(ols_fwd_olsrr, stars = TRUE)"
      ],
      "metadata": {
        "id": "XYsgDnv8QKWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model uses predictors identified via p-value-based stepwise selection `(ols_step_both_p())`, giving you a practical and statistically guided subset."
      ],
      "metadata": {
        "id": "2IZh4VZ8QUGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"gridExtra\")  # (Run once) For arranging multiple plots\n",
        "library(gridExtra)  # Load for grid-based plot arrangement\n",
        "\n",
        "# install.packages(\"sjPlot\")  # (Run once) For plotting model summaries\n",
        "library(sjPlot)  # Load for visualizing regression results\n",
        "\n",
        "p1 <- plot_model(ols_fwd_dredge,           # Use the model selected via MuMIn::dredge\n",
        "                 type = \"est\",             # Plot unstandardized coefficient estimates\n",
        "                 show.values = TRUE,       # Show the coefficient values next to the bars\n",
        "                 value.offset = 0.3,       # Offset distance for the displayed values\n",
        "                 title = \"OLSrr: Estimated\",  # Title for the plot\n",
        "                 vline.color = \"gray50\") +    # Color of the vertical zero reference line\n",
        "  theme_minimal()  # Apply a clean minimal theme\n",
        "\n",
        "# Optional standardized version (commented out)\n",
        "# p2 <- plot_model(ols_fwd_dredge,\n",
        "#                  type = \"std\",           # Plot standardized coefficients (beta)\n",
        "#                  show.values = TRUE,\n",
        "#                  value.offset = 0.3,\n",
        "#                  title = \"OLSrr: Standardized\",\n",
        "#                  vline.color = \"gray50\") +\n",
        "#   theme_minimal()\n",
        "\n",
        "grid.arrange(p1, ncol = 1)  # Display the plot(s) in a grid layout (here: just p1 in 1 column)"
      ],
      "metadata": {
        "id": "aCarXCnBQXOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This generates a visual summary of your regression coefficients, making it easier to interpret direction, size, and confidence intervals at a glance."
      ],
      "metadata": {
        "id": "vSEkfgWTQlYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"forestmodel\")  # (Run once) Install the 'forestmodel' package for forest-style coefficient plots\n",
        "\n",
        "library(forestmodel)  # Load the package\n",
        "\n",
        "forest_model(\n",
        "  ols_fwd_dredge,  # Use the final OLS model selected via MuMIn::dredge\n",
        "  theme = theme_forest(),  # Apply a clean, publication-ready forest plot theme\n",
        "  format_options = forest_model_format_options(text_size = 4)  # Adjust font size (smaller for compact display)\n",
        ")"
      ],
      "metadata": {
        "id": "rq2Vca4kQojn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a forest plot showing:\n",
        "- Coefficient estimates\n",
        "- 95% confidence intervals\n",
        "- Significance visually (whether CI crosses zero)"
      ],
      "metadata": {
        "id": "VMW8PjQ6Qve5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"see\")  # (Run once) Install 'see' for plotting model diagnostics\n",
        "\n",
        "library(performance)  # Load for model checking tools (residuals, multicollinearity, etc.)\n",
        "library(see)          # Load for visualizing performance checks\n",
        "\n",
        "check_model(ols_fwd_dredge)\n",
        "# Automatically generates a panel of diagnostic plots:\n",
        "# Residuals vs Fitted\n",
        "# Normal Q-Q\n",
        "# Scale-Location\n",
        "# Cookâ€™s Distance\n",
        "# Leverage\n",
        "# Multicollinearity (VIF)\n",
        "\n",
        "# Great for quickly checking:\n",
        "# - Linearity\n",
        "# - Homoscedasticity\n",
        "# - Influential observations\n",
        "# - Normality of residuals\n",
        "# - Multicollinearity"
      ],
      "metadata": {
        "id": "1ZY1_hPZQ1yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A simple guide to interpreting the plots from `check_model()` in plain English:**\n",
        "\n",
        "***Residuals vs Fitted***\n",
        "\n",
        "> What to look for: Points should be randomly scattered around the horizontal line (y = 0).\n",
        "> If you see a pattern (curve or funnel):\n",
        "- Your model may have non-linearity or heteroskedasticity.\n",
        "- Consider transforming variables or using a different model.\n",
        "\n",
        "\n",
        "***Normal Q-Q (Quantileâ€“Quantile Plot)***\n",
        "\n",
        "> What to look for: Points should follow the diagonal line.\n",
        "> If points deviate a lot at the ends:\n",
        "- Your residuals may not be normally distributed.\n",
        "- Normality matters most for inference (p-values, confidence intervals).\n",
        "\n",
        "***Scale-Location (Spreadâ€“Location Plot)***\n",
        "\n",
        "> What to look for: Points should be randomly spread with a flat trend.\n",
        "> If it fans out or has a pattern:\n",
        "- Your model may suffer from non-constant variance (heteroskedasticity).\n",
        "\n",
        "***Cookâ€™s Distance***\n",
        "\n",
        "> What to look for: Most points should be low and similar in height.\n",
        "- Tall spikes: Indicate influential points â€” data that heavily affects the model.\n",
        "- Investigate these â€” they may be valid outliers or data entry issues.\n",
        "\n",
        "***Leverage Plot***\n",
        "\n",
        "> What to look for: Most points should be close to the left.\n",
        "- Points far to the right: These have high leverage (unusual x-values).\n",
        "- If also high in Cookâ€™s Distance â†’ potentially problematic outlier.\n",
        "\n",
        "***Multicollinearity (VIF)***\n",
        "\n",
        "> What to look for: VIF values should ideally be < 5.\n",
        "- If VIF > 5â€“10: Suggests high multicollinearity â€” predictors may be too correlated.\n",
        "- Consider removing or combining variables."
      ],
      "metadata": {
        "id": "olsL9PA2RQgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required packages\n",
        "# install.packages(\"car\")       # (Run once) Provides tools like VIF and linearHypothesis\n",
        "# install.packages(\"lmtest\")    # (Run once) Provides tests like Breuschâ€“Pagan and Durbinâ€“Watson\n",
        "\n",
        "library(car)     # Load the 'car' package for regression diagnostics\n",
        "library(lmtest)  # Load the 'lmtest' package for hypothesis testing and autocorrelation checks\n",
        "\n",
        "# ---- 1. Model Summary ----\n",
        "cat(\"\\n Model Summary:\\n\")\n",
        "print(summary(ols_fwd_dredge))  # Display coefficients, R-squared, and p-values for your model\n",
        "\n",
        "# ---- 2. Multicollinearity Check ----\n",
        "cat(\"\\n Variance Inflation Factor (VIF):\\n\")\n",
        "print(vif(ols_fwd_dredge))  # Check if any predictors are too correlated (VIF > 5 or 10 is a concern)\n",
        "\n",
        "# ---- 3. Heteroskedasticity Test (Breuschâ€“Pagan) ----\n",
        "cat(\"\\n Breuschâ€“Pagan Test for Heteroskedasticity:\\n\")\n",
        "print(bptest(ols_fwd_dredge))  # Test whether residual variance is constant\n",
        "# If p < 0.05 â†’ your model may have heteroskedasticity (bad)\n",
        "\n",
        "# ---- 4. Autocorrelation Check (Durbin-Watson) ----\n",
        "cat(\"\\n Durbinâ€“Watson Test for Autocorrelation:\\n\")\n",
        "print(dwtest(ols_fwd_dredge))  # Test if residuals are correlated (esp. in time series)\n",
        "# DW ~ 2 is ideal. Much < 2 suggests positive autocorrelation\n",
        "\n",
        "# ---- 5. Normality of Residuals ----\n",
        "cat(\"\\n Shapiro-Wilk Test for Normality of Residuals:\\n\")\n",
        "print(shapiro.test(residuals(ols_fwd_dredge)))  # Test if residuals are normally distributed\n",
        "# p > 0.05 means residuals are likely normal (a good thing)\n",
        "\n",
        "# # ---- 6. Influence and Outlier Detection ----\n",
        "# cat(\"\\n Influential Observations (Cook's Distance > 4/n):\\n\")\n",
        "# cooks_d <- cooks.distance(ols_fwd_dredge)        # Measure how much each observation influences the model\n",
        "# n <- length(cooks_d)                             # Get the number of observations\n",
        "# influential_obs <- which(cooks_d > (4 / n))      # Flag observations with high influence\n",
        "# print(influential_obs)                           # Show their row numbers\n",
        "\n",
        "# # ---- 7. Joint Hypothesis Test (All team dummies = 0) ----\n",
        "# team_vars <- grep(\"^team\", names(coef(ols_fwd_dredge)), value = TRUE)  # Find all team dummy variables\n",
        "# cat(\"\\n Joint Significance Test for All Team Variables:\\n\")\n",
        "# print(linearHypothesis(ols_fwd_dredge, team_vars))  # Test if all team effects = 0 at once\n",
        "\n",
        "# ---- 8. Residual Plots (Optional) ----\n",
        "par(mfrow = c(2, 2))     # Arrange 4 plots in one 2x2 layout\n",
        "plot(ols_fwd_dredge)     # Generate diagnostic plots: residuals, Q-Q, leverage, etc.\n",
        "par(mfrow = c(1, 1))     # Reset to default plotting layout"
      ],
      "metadata": {
        "id": "LBSXa6xCRAGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(car)  # Load the 'car' package to use the VIF (Variance Inflation Factor) function\n",
        "\n",
        "# Define a function to reduce multicollinearity by stepwise VIF elimination\n",
        "vif_stepwise <- function(model, thresh = 5, trace = TRUE) {\n",
        "\n",
        "  vifs <- vif(model)  # Calculate initial VIFs for all predictors\n",
        "\n",
        "  while (any(vifs > thresh)) {  # Keep looping as long as at least one VIF exceeds the threshold\n",
        "\n",
        "    var_to_drop <- names(which.max(vifs))  # Find the variable with the highest VIF\n",
        "\n",
        "    if (trace) {\n",
        "      cat(\"Dropping:\", var_to_drop, \"| VIF =\", max(vifs), \"\\n\")  # Print which variable is being dropped\n",
        "    }\n",
        "\n",
        "    fmla <- formula(model)  # Extract the model formula\n",
        "    fmla <- update(fmla, paste(\". ~ . -\", var_to_drop))  # Update the formula by removing the high-VIF variable\n",
        "\n",
        "    model <- lm(fmla, data = model$model)  # Refit the model with the reduced formula\n",
        "    vifs <- vif(model)  # Recalculate VIFs\n",
        "  }\n",
        "\n",
        "  return(model)  # Return the final model with all VIFs below the threshold\n",
        "}"
      ],
      "metadata": {
        "id": "fEz5RiHLTHO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What this function does:\n",
        "- Automatically removes the most collinear variable one at a time (based on highest VIF).\n",
        "- Stops when all remaining VIFs are below the given threshold (default = 5).\n",
        "- Prints progress if trace = TRUE."
      ],
      "metadata": {
        "id": "sETOfvjyTPbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with full model (commented out here â€” assumed already defined)\n",
        "# ols_fwd_dredge <- lm(\n",
        "#     total_points ~ assists + creativity + expected_goals + goals_scored +\n",
        "#       influence + minutes + own_goals + penalties_missed + selected +\n",
        "#       starts + threat + value, data = db03)\n",
        "\n",
        "# Run VIF-guided backward selection\n",
        "ols_fwd_treated <- vif_stepwise(ols_fwd_dredge, thresh = 5)\n",
        "# This automatically drops predictors one by one if their VIF > 5,\n",
        "# reducing multicollinearity from the model\n",
        "\n",
        "# Review the refined model\n",
        "summary(ols_fwd_treated)\n",
        "# Shows the final model after removing collinear predictors:\n",
        "# includes coefficients, significance, and fit metrics"
      ],
      "metadata": {
        "id": "IWfaWiu5TUp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(car)      # For calculating Variance Inflation Factor (VIF)\n",
        "library(tibble)   # For tidy conversion of row names into a column\n",
        "library(dplyr)    # For data manipulation like sorting and renaming\n",
        "\n",
        "# Calculate VIF and convert result into a clean tibble\n",
        "vif_table <- vif(ols_fwd_treated) %>%          # Compute VIFs for all predictors in the treated model\n",
        "  as.data.frame() %>%                          # Convert the named vector to a data frame\n",
        "  rownames_to_column(var = \"Variable\") %>%     # Move variable names from row names to a column\n",
        "  rename(VIF = \".\")                            # Rename the automatically generated column \".\" to \"VIF\"\n",
        "\n",
        "# Optionally sort variables by descending VIF value\n",
        "vif_table <- vif_table %>%\n",
        "  arrange(desc(VIF))\n",
        "\n",
        "# Print the final clean VIF table\n",
        "print(vif_table)"
      ],
      "metadata": {
        "id": "jRR3GGwOTeDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"estimatr\")  # (Run once) For robust standard errors\n",
        "library(estimatr)  # Load if using lm_robust\n",
        "\n",
        "# install.packages(\"modelsummary\")  # (Optional) For clean regression tables\n",
        "# library(modelsummary)\n",
        "\n",
        "# (Optional robust version with heteroskedasticity-consistent standard errors)\n",
        "# ols_fwd_trtd <- lm_robust(\n",
        "#     total_points ~ assists + creativity + expected_goals +\n",
        "#     goals_scored + own_goals + penalties_missed +\n",
        "#     selected + starts + threat + value, data = db03, se_type = \"stata\")\n",
        "\n",
        "# Standard OLS regression using final, low-multicollinearity predictors\n",
        "ols_fwd_trtd <- lm(\n",
        "  total_points ~ assists + creativity + expected_goals +\n",
        "    goals_scored + own_goals + penalties_missed +\n",
        "    selected + starts + threat + value, data = db03)\n",
        "\n",
        "summary(ols_fwd_trtd)\n",
        "# Print model summary: coefficients, p-values, RÂ², and diagnostic info\n",
        "\n",
        "# Optional: create a clean, publication-style summary table\n",
        "# modelsummary(ols_fwd_trtd, stars = TRUE)"
      ],
      "metadata": {
        "id": "ukHtP_lUTkuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(forestmodel)  # Load the package to create forest plots for regression models\n",
        "\n",
        "# Create forest plot object from final OLS model\n",
        "p_forest <- forest_model(\n",
        "  ols_fwd_trtd,                         # Use the VIF-treated regression model\n",
        "  theme = theme_forest(),              # Apply a clean forest-style theme\n",
        "  format_options = forest_model_format_options(text_size = 4)  # Set small font for compact display\n",
        ")\n",
        "\n",
        "# Save the plot to a PDF file\n",
        "pdf(\"/content/drive/MyDrive/00fpl/forest_plot.pdf\", width = 11.69, height = 8.27)\n",
        "# Open a PDF device (A4 landscape size) to save the plot\n",
        "\n",
        "# Arrange and render the plot\n",
        "grid.arrange(\n",
        "  grobs = list(p_forest),  # Put the forest plot in a list (can add more plots later)\n",
        "  ncol = 1                  # Arrange in 1 column (i.e., single full-page plot)\n",
        ")\n",
        "\n",
        "dev.off()  # Close the PDF device and finalize the file"
      ],
      "metadata": {
        "id": "mIvfyRNETth2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"gridExtra\")  # (Run once) For arranging plots\n",
        "library(gridExtra)  # Load to use grid.arrange()\n",
        "\n",
        "# install.packages(\"sjPlot\")  # (Run once) For visualizing regression models\n",
        "library(sjPlot)  # Load to use plot_model()\n",
        "\n",
        "# Create a standardized coefficient plot\n",
        "p_sj <- plot_model(\n",
        "  ols_fwd_trtd,                    # Use the final VIF-treated OLS model\n",
        "  type = \"std\",                    # Plot standardized beta coefficients\n",
        "  show.values = TRUE,              # Display coefficient values on the plot\n",
        "  value.offset = 0.3,              # Move the text slightly away from the bars\n",
        "  title = \"OLSrr: Standardized\",  # Title for the plot\n",
        "  vline.color = \"gray50\"           # Vertical reference line at zero\n",
        ") +\n",
        "  theme_minimal()                  # Apply a clean theme\n",
        "\n",
        "# Save the plot as a landscape A4 PDF\n",
        "pdf(\"/content/drive/MyDrive/00fpl/sj_plot.pdf\", width = 11.69, height = 8.27)\n",
        "# Open a PDF device to write the plot\n",
        "\n",
        "# Render the plot into the PDF\n",
        "grid.arrange(\n",
        "  grobs = list(p_sj),  # Place the plot into a list of grobs (plot objects)\n",
        "  ncol = 1              # Arrange in 1 column\n",
        ")\n",
        "\n",
        "dev.off()  # Finalize and close the PDF device"
      ],
      "metadata": {
        "id": "s89z80UmT096"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install.packages(\"stargazer\")  # (Run once) Install stargazer for beautiful regression tables\n",
        "library(stargazer)  # Load stargazer for formatting regression output\n",
        "\n",
        "# Export a side-by-side regression table for 3 models\n",
        "stargazer(\n",
        "  ols_fwd_stepwise,                # Model from stepwise selection\n",
        "  ols_fwd_dredge,                  # Model from AICc selection via MuMIn::dredge\n",
        "  ols_fwd_trtd,                    # Final model after VIF filtering\n",
        "  type = \"text\",                   # Output format: plain text (other options: \"html\", \"latex\")\n",
        "  out = \"/content/drive/MyDrive/00fpl/ols_fwd_estimatr.txt\"  # Save output to this text file\n",
        ")"
      ],
      "metadata": {
        "id": "IKTY3qt8T9dZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}